{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cefbc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import netCDF4\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import cartopy as cart\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime, timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25894ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "\n",
    "def jd_to_date(jd):\n",
    "    \"\"\"\n",
    "    Convert Julian Day to date.\n",
    "    \n",
    "    Algorithm from 'Practical Astronomy with your Calculator or Spreadsheet', \n",
    "        4th ed., Duffet-Smith and Zwart, 2011.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    jd : float\n",
    "        Julian Day\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    year : int\n",
    "        Year as integer. Years preceding 1 A.D. should be 0 or negative.\n",
    "        The year before 1 A.D. is 0, 10 B.C. is year -9.\n",
    "        \n",
    "    month : int\n",
    "        Month as integer, Jan = 1, Feb. = 2, etc.\n",
    "    \n",
    "    day : float\n",
    "        Day, may contain fractional part.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    Convert Julian Day 2446113.75 to year, month, and day.\n",
    "    \n",
    "    >>> jd_to_date(2446113.75)\n",
    "    (1985, 2, 17.25)\n",
    "    \n",
    "    \"\"\"\n",
    "    jd = jd + 0.5\n",
    "    \n",
    "    F, I = math.modf(jd)\n",
    "    I = int(I)\n",
    "    \n",
    "    A = math.trunc((I - 1867216.25)/36524.25)\n",
    "    \n",
    "    if I > 2299160:\n",
    "        B = I + 1 + A - math.trunc(A / 4.)\n",
    "    else:\n",
    "        B = I\n",
    "        \n",
    "    C = B + 1524\n",
    "    \n",
    "    D = math.trunc((C - 122.1) / 365.25)\n",
    "    \n",
    "    E = math.trunc(365.25 * D)\n",
    "    \n",
    "    G = math.trunc((C - E) / 30.6001)\n",
    "    \n",
    "    day = C - E + F - math.trunc(30.6001 * G)\n",
    "    \n",
    "    if G < 13.5:\n",
    "        month = G - 1\n",
    "    else:\n",
    "        month = G - 13\n",
    "        \n",
    "    if month > 2.5:\n",
    "        year = D - 4716\n",
    "    else:\n",
    "        year = D - 4715\n",
    "        \n",
    "    return year, month, day\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def jd_to_datetime(jd):\n",
    "    \"\"\"\n",
    "    Convert a Julian Day to an `jdutil.datetime` object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    jd : float\n",
    "        Julian day.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dt : `jdutil.datetime` object\n",
    "        `jdutil.datetime` equivalent of Julian day.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> jd_to_datetime(2446113.75)\n",
    "    datetime(1985, 2, 17, 6, 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    year, month, day = jd_to_date(jd)\n",
    "    \n",
    "    frac_days,day = math.modf(day)\n",
    "    day = int(day)\n",
    "    \n",
    "    hour,min,sec,micro = days_to_hmsm(frac_days)\n",
    "    \n",
    "    return datetime(year,month,day,hour,min,sec,micro)\n",
    "\n",
    "\n",
    "def days_to_hmsm(days):\n",
    "    \"\"\"\n",
    "    Convert fractional days to hours, minutes, seconds, and microseconds.\n",
    "    Precision beyond microseconds is rounded to the nearest microsecond.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    days : float\n",
    "        A fractional number of days. Must be less than 1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    hour : int\n",
    "        Hour number.\n",
    "    \n",
    "    min : int\n",
    "        Minute number.\n",
    "    \n",
    "    sec : int\n",
    "        Second number.\n",
    "    \n",
    "    micro : int\n",
    "        Microsecond number.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `days` is >= 1.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> days_to_hmsm(0.1)\n",
    "    (2, 24, 0, 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    hours = days * 24.\n",
    "    hours, hour = math.modf(hours)\n",
    "    \n",
    "    mins = hours * 60.\n",
    "    mins, min = math.modf(mins)\n",
    "    \n",
    "    secs = mins * 60.\n",
    "    secs, sec = math.modf(secs)\n",
    "    \n",
    "    micro = round(secs * 1.e6)\n",
    "    \n",
    "    return int(hour), int(min), int(sec), int(micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee57d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose Data Location\n",
    "\n",
    "location = 'work'\n",
    "\n",
    "if location in {'work'} :\n",
    "    main_path = r\"/DGFI8/H/work_marcello/giussani_machinelearning_data/\"\n",
    "    #directory = main_path + 'DMI_HBM'\n",
    "    directory = main_path + 'BALTICSEA_REANALYSIS_PHY_003_011'\n",
    "    directory_cmems=main_path + 'SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047' \n",
    "    directory_dac=r\"/nfs/DGFI8/D/ERAinterim/2004/\"#main_path + 'DAC'\n",
    "    directory_grid = main_path + 'BALTICSEA_ML_GRID'\n",
    "\n",
    "elif location in {'laptop'} :\n",
    "    main_path = r\"C:\\Users\\ne62rut\\Documents\\giussani_machinelearning_data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82199b5",
   "metadata": {},
   "source": [
    "Extract DAC Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07384947",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "#print(cur_dir)\n",
    "parent_dir = os.path.dirname(cur_dir)\n",
    "#print(parent_dir)\n",
    "\n",
    "file_list=[]\n",
    "\n",
    "for file in os.listdir(directory_dac):\n",
    "    if (file.endswith(\".nc\")) :\n",
    "        file_list.append(os.path.join(directory_dac, file))\n",
    "\n",
    "track_counter = 1\n",
    "\n",
    "for z in file_list[0:np.size(file_list)]: \n",
    "    \n",
    "    #CNES Julian Day is in z[-11:-3]\n",
    "    \n",
    "    if track_counter == 1 :\n",
    "        ds_dac = xr.open_dataset(z)\n",
    "        time=jd_to_datetime( int(z[-11:-6] ) + 2433282.5 )\n",
    "        time = time + timedelta(hours=int(z[-5:-3])) \n",
    "        ds_dac = ds_dac.assign_coords({\"time\": time})\n",
    "        ds_dac  = ds_dac.expand_dims('time')\n",
    "        \n",
    "\n",
    "        track_counter = track_counter +1\n",
    "    else :\n",
    "\n",
    "        ds_dac_temp = xr.open_dataset(z)\n",
    "        time=jd_to_datetime( int(z[-11:-6] ) + 2433282.5 )\n",
    "        time = time + timedelta(hours=int(z[-5:-3])) \n",
    "        ds_dac_temp = ds_dac_temp.assign_coords({\"time\": time})\n",
    "        ds_dac_temp  = ds_dac_temp.expand_dims('time')        \n",
    "        \n",
    "        ds_dac = xr.concat([ ds_dac , ds_dac_temp ], dim='time')\n",
    "        track_counter = track_counter +1\n",
    "        \n",
    "ds_dac = ds_dac.where( ( (ds_dac.longitude < 31.0) & (ds_dac.longitude > 9.0) &   \\\n",
    "                           (ds_dac.latitude < 66.0) & (ds_dac.latitude > 53.0) )  , drop=True)\n",
    "\n",
    "ds_dac = ds_dac.sortby(ds_dac.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465ffe0",
   "metadata": {},
   "source": [
    "# LOAD  DATA BALTIC SEA REANALYSIS (Copernicus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6944b54",
   "metadata": {},
   "source": [
    "The model data are first corrected for the corresponding DAC and then averaged as daily means to match the altimetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de79f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_for_dac(ds,ds_dac):\n",
    "    ds_dac_interp = ds_dac.copy(deep=False) #save backup of hourly values for further verification\n",
    "    ds_dac_interp = ds_dac_interp.interp(longitude=ds.longitude, latitude=ds.latitude, time = ds.time)\n",
    "\n",
    "    ds = ds.assign(sla_with_dac= ds[\"sla\"] - ds_dac_interp[\"dac\"])\n",
    "\n",
    "    ds = ds.rename({'sla': 'TWLE'})\n",
    "    ds = ds.rename({'sla_with_dac': 'sla'})    \n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "#glob.glob('./[0-9].*')\n",
    "cur_dir = os.getcwd()\n",
    "#print(cur_dir)\n",
    "parent_dir = os.path.dirname(cur_dir)\n",
    "#print(parent_dir)\n",
    "file_list=[]\n",
    "for root, dirs, files in os.walk(directory):  \n",
    "    for file in files :\n",
    "        if (file.endswith(\".nc\")) :\n",
    "            file_list.append(os.path.join(root, file))\n",
    "\n",
    "track_counter = 1\n",
    "\n",
    "for z in file_list[0:np.size(file_list)]: \n",
    "#for z in file_list[0:12]: #Try with 2 tracks\n",
    "    \n",
    "    if track_counter == 1 :\n",
    "        ds = xr.open_dataset(z)\n",
    "        ds = correct_for_dac(ds,ds_dac)\n",
    "        ds = ds.resample(time=\"1D\").mean() #data are hourly. compute daily means.\n",
    "        track_counter = track_counter +1\n",
    "    else :\n",
    "        daily_mean = xr.open_dataset(z)\n",
    "        daily_mean = correct_for_dac(daily_mean,ds_dac)\n",
    "        daily_mean = daily_mean.resample(time=\"1D\").mean() #data are hourly. compute daily means.\n",
    "        ds = xr.concat([ ds , daily_mean ], dim='time')\n",
    "        track_counter = track_counter +1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931d3df",
   "metadata": {},
   "source": [
    "Sort by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28bdd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sortby(ds.time)\n",
    "#ds.sla[156].plot(vmin=-2, vmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3cfce9",
   "metadata": {},
   "source": [
    "# Save datasets as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388f6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use format of Baltic+ Grids\n",
    "cur_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(cur_dir)\n",
    "file_list_grid=[]\n",
    "for file in os.listdir(directory_grid):\n",
    "    if (file.startswith(\"BALTIC\")) :\n",
    "        file_list_grid.append(os.path.join(directory_grid, file))\n",
    "#ds_grid = xr.open_dataset(file_list_grid[0])\n",
    "ds_grid = pd.read_csv(file_list_grid[0])\n",
    "\n",
    "time_surge = pd.date_range(start='01/01/2004', end='31/12/2004', freq='24H')\n",
    "\n",
    "ds_forprediction = xr.Dataset(\n",
    "    {\n",
    "        \"sla\": ([\"times\"], np.tile( np.ones(np.shape(time_surge)),np.size(ds_grid.lon.values)) ),\n",
    "        \"lon\": ([\"times\"], np.repeat(ds_grid.lon.values, np.size(time_surge) ) ),\n",
    "        \"lat\": ([\"times\"], np.repeat(ds_grid.lat.values, np.size(time_surge) ) ),\n",
    "        \"time_model\": ([\"times\"], np.tile(time_surge,np.size(ds_grid.lon.values)) )\n",
    "    },\n",
    "    coords={\n",
    "        \"longitude\": ([\"times\"],np.repeat(ds_grid.lon.values, np.size(time_surge)  ) ),\n",
    "        \"latitude\": ([\"times\"], np.repeat(ds_grid.lat.values, np.size(time_surge)  ) ),\n",
    "        \"time\": ([\"times\"],np.tile(time_surge,np.size(ds_grid.lon.values)))\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4fe2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate model data onto the altimetry tracks\n",
    "dsi_forprediction = ds.interp(longitude=ds_forprediction.lon, latitude=ds_forprediction.lat, time = ds_forprediction.time_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into dataframe and drop NaN\n",
    "dsi_forprediction = dsi_forprediction.to_dataframe()\n",
    "\n",
    "dsi_forprediction = dsi_forprediction.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adfd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi_forprediction=dsi_forprediction.rename(columns={\"sla\": \"sla_predicted\", \"longitude\": \"lon\", \"latitude\": \"lat\"})\n",
    "\n",
    "dsi_forprediction.to_csv('/DGFI8/H/work_marcello/machine_learning_altimetry/test_prediction_newpoints_surge_copernicus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517297be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correct ML altimetry for DAC\n",
    "# # Altimetry\n",
    "# alti = pd.read_csv(r'test_prediction_newpoints_surge_newtraining.csv')\n",
    "\n",
    "# alti_dataset = xr.Dataset(\n",
    "#     {\n",
    "#         \"sla_predicted\": ([\"times\"], alti.sla_predicted ),\n",
    "#         \"lon\": ([\"times\"], alti.lon ),\n",
    "#         \"lat\": ([\"times\"], alti.lat ),\n",
    "#         \"time_model\": ([\"times\"], pd.to_datetime(alti.time) )\n",
    "#     },\n",
    "#     coords={\n",
    "#         \"longitude\": ([\"times\"],alti.lon ),\n",
    "#         \"latitude\": ([\"times\"], alti.lat ),\n",
    "#         \"time\": ([\"times\"],pd.to_datetime(alti.time))\n",
    "#     },\n",
    "# )\n",
    "\n",
    "\n",
    "# ds_dac_alti = ds_dac.interp(longitude=alti_dataset.lon, latitude=alti_dataset.lat, time = alti_dataset.time)\n",
    "\n",
    "# alti_dataset = alti_dataset.assign(sla_predicted= alti_dataset[\"sla_predicted\"] + ds_dac_alti[\"dac\"])\n",
    "# #alti_dataset = alti_dataset.assign(sla_predicted= alti_dataset[\"sla_predicted\"] )\n",
    "# alti_dataset= alti_dataset.to_dataframe()\n",
    "# alti_dataset = alti_dataset.dropna()\n",
    "# alti_dataset = alti_dataset.drop(columns=['time_model', 'longitude','latitude'])\n",
    "# alti_dataset.to_csv('test_prediction_newpoints_surge_newtraining_withdac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be178042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
